{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb9e777",
   "metadata": {},
   "source": [
    "# Logging for ML Model Deployments\n",
    "\n",
    "In previous blog posts we [introduced the decorator pattern](https://www.tekhnoal.com/ml-model-decorators.html) for ML model deployments and then showed how to use the pattern to build extensions for a ML model deployment. For example, in [this blog post](https://www.tekhnoal.com/data-enrichment-for-ml-models.html) we did data enrichment using a PostgreSQL database. The extensions were added without having to modify the machine learning model code at all, we were able to do it by using the decorator pattern. In this blog post weâ€™ll add logging to a model deployment without having to modify the model code, using a decorator. In this blog post, we'll show how to use the decorator pattern to add logging functionality to an ML model.\n",
    "\n",
    "This blog post is written in a Jupyter notebook and we'll be switching between Python code and shell commands, the formatting will reflect this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0503f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As software systems become more and more complex, the people that build and operate these systems are finding that they are very hard to debug and inspect. To be able to solve this issue, a software system needs to be observable. An observable system is a system that allows an outside observer to infer the internal state of the system based purely on the data that it generates. The quality of \"observability\" helps the operators of a system to understand the inner workings of the system and to solve issues that may come up, even when the issues may be unprecedented.\n",
    "\n",
    "Observability is a non-functional requirement (NFR) of a system. An NFR is a requirement that is placed on the operation of a system that has nothing to do with the specific functions of the system. Rather, it is a cross-cutting concern that needs to be addressed within the whole system design. Logging is a way that we can implement observability of a software system. \n",
    "\n",
    "In the world of software systems, a \"log\" is a record of events that happen as software runs. A log is made up of individual records called log records that each represent a single event in the software system. Logs are useful for debugging the system, keeping a permanent record of it's activities, and many other purposes. \n",
    "\n",
    "A log record can be made of any data, but is usually encoded as text which makes a log record easy to create and read by humans. A log record can contain many pieces of information, but the most common are the date and time when the log record was created, a unique identifier for the log record, and some description of the event that caused the log record to be created. Logs are also usually tagged with the level of the severity of the event, for example an exception thrown during the execution of a program can be a handled or it can stop the execution, in either case a log can be generated with the correct level of the log. In general, log records are designed for debugging, alerting, and auditing the activities of the system.\n",
    "\n",
    "Just like any other software component, machine learning models need to create a log of events that may be useful later on. For example, we may want to know how many predictions the model made, how many errors occurred, and any other interesting events that we may want to keep track of. In this blog post we'll create a decorator that creates a log for a machine learning model.\n",
    "\n",
    "This post is not meant to be a full guide for doing logging in Python, but we'll include some background information to make it easier to understand. Logging in Python can get complicated and there are other places that cover it more thoroughly. [Here](https://realpython.com/python-logging/) is a good place to learn more about Python logging.\n",
    "\n",
    "All of the code is available in [this github repository](https://github.com/schmidtbri/logging-for-ml-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587187c1",
   "metadata": {},
   "source": [
    "## Software Architecture\n",
    "\n",
    "The logging decorator will operate within the model service, but it requires outside services to handle the logs that it produces. This makes the software architecture more complicated and requires that we add several more services to the mix. \n",
    "\n",
    "![Software Architecture](software_architecture_lfmlm.png)\n",
    "![Software Architecture]({attach}software_architecture_lfmlm.png){ width=100% }\n",
    "\n",
    "The logging decorator is executing right after the prediction request is received from the client and a prediction is made by the model, it will send logs to be handled by other services. The other services are:\n",
    "\n",
    "- Log Forwarder: a service that runs on each cluster node that forwards logs from the local hard drive to the log aggregator service.\n",
    "- Log Aggregator: a network service that receives logs from many sources, processes them, and formats them for the log storage service.\n",
    "- Log Storage: a network service that can store logs and also query them.\n",
    "- Log User Interface: a network service with a web interface that provides access to the logs stored in the log storage service.\n",
    "\n",
    "The specific services that we'll use will be detailed later in the blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fbac3",
   "metadata": {},
   "source": [
    "## Logging Best Practices\n",
    "\n",
    "There are certain things that we can do when we create a log for our application that makes it more useful, especially in productions settings. For example, attaching a \"level\" to each log record makes it easy to filter the log according to the severity of the events. For example, a log record is of level \"INFO\" when it communicates a simple action that the system has taken. A \"WARNING\" log event is an event that may indicate a problem in the system, but the system can continue to run. A good description of the common log levels is [here](https://sematext.com/blog/logging-levels/).\n",
    "\n",
    "Another good practice for logs is to include contextual information that can help to debug any problems that may arise in the execution of the code. For example, we can include the location in the codebase where the log record was generated. This information is very helpful during debugging and helps to quickly find the code that caused the event to happen. The information is often presented as the function name, code file name, and line number where the log message was generated. Another piece of useful contextual information is the hostname of the machine where the log was generated.\n",
    "\n",
    "Logs should be easy to interpret for both humans and machines, this means that log records  are often written in text strings. Humans can easily read text, but parsing a text string is complicated for machines. To allow both humans and machines to easily parse a log message, a good middle ground is to use JSON formatting. JSON-formatted logs are easy to parse, but also allow a human to quickly read and understand a log message.\n",
    "\n",
    "Unique identifiers are useful to include in logs because they allow us to correlate many different log records together into a cohesive picture. For example, a correlation id is a unique ID that is generated to identify a specific transaction or query in a system. Adding unique identifiers to each log record can make it possible to debug complex problems that happen across system boundaries. A good description of correlation ids is [here](https://hilton.org.uk/blog/microservices-correlation-id)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c74e0",
   "metadata": {},
   "source": [
    "## Logging in Python\n",
    "\n",
    "The python standard library has a module that can simplify logging. The logging module imported and used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c4469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.warning(\"Warning message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3efbe",
   "metadata": {},
   "source": [
    "To start logging, we instantiated a logger object using the logging.getLogger() function. Then we used the logger object to log a WARNING message.\n",
    "\n",
    "The log records are being sent to the stderr output of the process by default. We'll change that by instantiating a StreamHandler and pointing it at the stdout stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0718fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning message.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "logger.addHandler(stream_handler)\n",
    "logger.warning(\"Warning message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4192a9",
   "metadata": {},
   "source": [
    "We can also log messages at other levels, here is a WARNING and DEBUG message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87c502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning message.\n"
     ]
    }
   ],
   "source": [
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e2b34",
   "metadata": {},
   "source": [
    "When the code above executed, only the WARNING message was printed because the logger only sends log messages to the output that are at the WARNING level or above by default. This filtering functionality is helpful when you are only interested in logs above a certain level. We can change that by configuring the logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b301d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning message.\n",
      "Debug message.\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698dcbd",
   "metadata": {},
   "source": [
    "We can put in more information to the log record by adding a formatter to the log handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c708ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:06:30,163:root:WARNING: Warning message.\n",
      "2022-06-12 18:06:30,165:root:DEBUG: Debug message.\n"
     ]
    }
   ],
   "source": [
    "formatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s: %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b381a",
   "metadata": {},
   "source": [
    "The log record now contains the date and time of the event, the name of the logger that generated the message, the level of the log, and the log message.\n",
    "\n",
    "Each logger has a name attached to it when it is created, the name of the current logger is \"root\" because it is the first logger created. We can create a new logger with a name like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55baffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:06:32,442:test_logger:DEBUG: Debug message.\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"test_logger\")\n",
    "\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c8b04",
   "metadata": {},
   "source": [
    "The log record has the name of the logger. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec68e51",
   "metadata": {},
   "source": [
    "### Logging the Hostname\n",
    "\n",
    "To log extra information that is not available by the default within the logger we have to extend the logging module by creating Filter classes. A Filter is simply a class that accepts log records and can modify them. \n",
    "\n",
    "We'll add the hostname of the machine where the process is running to the log records by creating a Filter class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebb278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "\n",
    "class HostnameFilter(logging.Filter):\n",
    "    \"\"\"Logging filter that adds the hostname to log records.\"\"\"\n",
    "\n",
    "    def filter(self, record):\n",
    "        record.hostname = platform.uname()[1]\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d693963",
   "metadata": {},
   "source": [
    "To use the HostnameFilter class, we'll instantiate it and add it to the logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1575264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname_filter = HostnameFilter()\n",
    "\n",
    "logger.addFilter(hostname_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca562fab",
   "metadata": {},
   "source": [
    "To actually add the hostname to the log record, we'll need to modify the format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7bd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:06:41,878:test_logger:WARNING:Brians-MBP.attlocal.net:Warning message.\n",
      "2022-06-12 18:06:41,880:test_logger:DEBUG:Brians-MBP.attlocal.net:Debug message.\n"
     ]
    }
   ],
   "source": [
    "formatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s:%(hostname)s:%(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664d779",
   "metadata": {},
   "source": [
    "The name of the field added to the log record is \"hostname\" so to add it to a log record we needed to add \"%(hostname)s\" to the format string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa766a6c",
   "metadata": {},
   "source": [
    "### Logging Environment Variables\n",
    "\n",
    "We may want to add more contextual information to the log in the future. This information will come from the environment variables of the process in which the logger is running. To do this we'll create another Filter that is able to pick up information from the environment variables. This filter is more interesting because it needs to be configured with the names of the environment variables that it needs to add to the log records.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6551ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class EnvironmentInfoFilter(logging.Filter):\n",
    "    \"\"\"Logging filter that adds information to log records from environment variables.\"\"\"\n",
    "    \n",
    "    def __init__(self, env_variables: List[str]):\n",
    "        super().__init__()\n",
    "        self._env_variables = env_variables\n",
    "\n",
    "    def filter(self, record):\n",
    "        for env_variable in self._env_variables:\n",
    "            record.__setattr__(env_variable.lower(), os.environ.get(env_variable, \"N/A\"))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13352e",
   "metadata": {},
   "source": [
    "To try it out we'll have to add an environment variable that will be logged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60011af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NODE_IP\"] = \"198.197.196.195\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ac84b",
   "metadata": {},
   "source": [
    "Next, we'll instantiate the Filter class and add it to a logger instance to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced21823",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_info_filter = EnvironmentInfoFilter(env_variables=[\"NODE_IP\"])\n",
    "\n",
    "logger.addFilter(environment_info_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475fabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:07:47,284:test_logger:WARNING:Brians-MBP.attlocal.net:198.197.196.195:Warning message.\n",
      "2022-06-12 18:07:47,285:test_logger:DEBUG:Brians-MBP.attlocal.net:198.197.196.195:Debug message.\n"
     ]
    }
   ],
   "source": [
    "formatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s:%(hostname)s:%(node_ip)s:%(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.warning(\"Warning message.\")\n",
    "logger.debug(\"Debug message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644cd2e",
   "metadata": {},
   "source": [
    "The log record now contains the IP address that we set in the environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae437b1",
   "metadata": {},
   "source": [
    "### Logging in JSON\n",
    "\n",
    "So far, the logs we've been generated have been in a slightly structured format that we came up with. It uses colons to separate out different sections of the log record. If we want to easily parse the logs, we should instead use JSON records. In this section we'll use the python-json-logger package to format the log records as JSON strings. \n",
    "\n",
    "First, we'll install the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d365f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install python-json-logger\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ab922",
   "metadata": {},
   "source": [
    "We'll instantiate a JsonFormatter object that will conver the logs to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7015f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "\n",
    "json_formatter = jsonlogger.JsonFormatter(\"%(asctime)s:%(name)s:%(levelname)s:\"\n",
    "                                          \"%(hostname)s:%(node_ip)s:%(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cae09",
   "metadata": {},
   "source": [
    "We'll add the formatter to the stream handler that we created above like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2029c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_handler.setFormatter(json_formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f822b",
   "metadata": {},
   "source": [
    "Now when we log, the output will be a JSON string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "205fc603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 18:07:58,346\", \"name\": \"test_logger\", \"levelname\": \"ERROR\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"message\": \"Error message.\"}\n"
     ]
    }
   ],
   "source": [
    "logger.error(\"Error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7f3c9",
   "metadata": {},
   "source": [
    "We can add easily add more fields from the log record to make it more comprehensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f33d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 18:08:02,496\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/469864656.py\", \"lineno\": 8, \"levelname\": \"ERROR\", \"message\": \"Error message.\"}\n"
     ]
    }
   ],
   "source": [
    "json_formatter = jsonlogger.JsonFormatter(\n",
    "    \"%(asctime)s %(hostname)s %(node_ip)s \"\n",
    "    \"%(process)s %(thread)s %(pathname)s \"\n",
    "    \"%(lineno)s %(levelname)s %(message)s\")\n",
    "\n",
    "stream_handler.setFormatter(json_formatter)\n",
    "\n",
    "logger.error(\"Error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a35a1",
   "metadata": {},
   "source": [
    "The JSON formatter can also add extra fields to the log record by using the \"extra\" parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93a7a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 18:08:04,808\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/1433050719.py\", \"lineno\": 9, \"levelname\": \"ERROR\", \"message\": \"message\", \"action\": \"predict\", \"model_qualified_name\": \"model_qualified_name\", \"model_version\": \"model_version\", \"status\": \"error\", \"error_info\": \"error_info\"}\n"
     ]
    }
   ],
   "source": [
    "extra = {\n",
    "    \"action\": \"predict\",\n",
    "    \"model_qualified_name\": \"model_qualified_name\",\n",
    "    \"model_version\": \"model_version\",\n",
    "    \"status\":\"error\",\n",
    "    \"error_info\": \"error_info\"\n",
    "}\n",
    "\n",
    "logger.error(\"message\", extra=extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722888a",
   "metadata": {},
   "source": [
    "The extra fields are:\n",
    "\n",
    "- action: the method called on the MLModel instance\n",
    "- model_qualified_name: the qualified name of the model\n",
    "- model_version: the version of the model\n",
    "- status: whether the action succeeded or not, can be \"success\" or \"error\"\n",
    "- error_info:\n",
    "\n",
    "This information would normally be included in the \"message\" field of the log record as unstructured text, but by breaking it out and putting it into individual fields in the JSON log record we'll be able to parse it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740a147",
   "metadata": {},
   "source": [
    "### Putting It All Together\n",
    "\n",
    "We've done a few things with the logger module, now we need to put it all together into one configuration that we can use to set up the logger the way we want it.\n",
    "\n",
    "The logging.config.dictConfig() function can accept all of the options of the loggers, formatters, handlers, and filters and set them up with one function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d801277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging.config\n",
    "\n",
    "\n",
    "logging_config = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": True,\n",
    "    \"formatters\": {\n",
    "        \"json_formatter\": {\n",
    "            \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n",
    "            \"format\": \"%(asctime)s %(hostname)s %(node_ip)s %(process)s %(thread)s %(pathname)s %(lineno)s %(levelname)s %(message)s\"\n",
    "        }\n",
    "    },\n",
    "    \"filters\": {\n",
    "        \"hostname_filter\": {\n",
    "            \"()\": \"__main__.HostnameFilter\"            \n",
    "        },\n",
    "        \"environment_info_filter\": {\n",
    "            \"()\": \"__main__.EnvironmentInfoFilter\",\n",
    "            \"env_variables\": [\"NODE_IP\"]\n",
    "        }\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"stdout\":{\n",
    "            \"level\":\"INFO\",\n",
    "            \"class\":\"logging.StreamHandler\",\n",
    "            \"stream\": \"ext://sys.stdout\",\n",
    "            \"formatter\": \"json_formatter\",\n",
    "            \"filters\": [\"hostname_filter\", \"environment_info_filter\"]\n",
    "        }\n",
    "    },\n",
    "    \"loggers\": {\n",
    "        \"root\": {\n",
    "            \"level\": \"INFO\",\n",
    "            \"handlers\": [\"stdout\"],\n",
    "            \"propagate\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "674b3a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 18:08:17,392\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/4067465749.py\", \"lineno\": 4, \"levelname\": \"INFO\", \"message\": \"Info message.\"}\n",
      "{\"asctime\": \"2022-06-12 18:08:17,394\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/4067465749.py\", \"lineno\": 5, \"levelname\": \"ERROR\", \"message\": \"Error message.\"}\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "logger.debug(\"Debug message.\")\n",
    "logger.info(\"Info message.\")\n",
    "logger.error(\"Error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377be12",
   "metadata": {},
   "source": [
    "The logger behaved in the same way as when we created it programatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ccd2e",
   "metadata": {},
   "source": [
    "## Installing a Model\n",
    "\n",
    "We won't be training an ML model from scratch in this blog post because it would take a lot of space in the post. We'll be reusing a model that we built in a [previous blog post](https://www.tekhnoal.com/regression-model.html). The model's code is hosted in [this github repository](https://github.com/schmidtbri/regression-model). The model is able to predict  health insurance premiums.\n",
    "\n",
    "The model itself can be installed as a normal Python package, using the pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bce98912",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e git+https://github.com/schmidtbri/regression-model#egg=insurance_charges_model\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfaeda",
   "metadata": {},
   "source": [
    "Making a prediction with the model is done through the InsuranceChargesModel class, which we'll import like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a33f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.model import InsuranceChargesModel\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059299e",
   "metadata": {},
   "source": [
    "Now we'll instantiate the model class in order to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86688515",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceChargesModel()\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d11f3",
   "metadata": {},
   "source": [
    "In order to make a prediction with the model instance, we'll need to instantiate the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd6c215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.schemas import InsuranceChargesModelInput, \\\n",
    "    SexEnum, RegionEnum\n",
    "\n",
    "model_input = InsuranceChargesModelInput(\n",
    "    age=25, \n",
    "    sex=SexEnum.male,\n",
    "    bmi=21.0,\n",
    "    children=0,\n",
    "    smoker=False,\n",
    "    region=RegionEnum.northwest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29a143",
   "metadata": {},
   "source": [
    "The model's input schema is called InsuranceChargesModelInput and it holds all of the features required by the model to make a prediction.\n",
    "\n",
    "Now we can make a prediction with the model by calling the predict() method with an instance of the InsuranceChargesModelInput class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e880f111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=2696.69)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87fd91",
   "metadata": {},
   "source": [
    "The model predicts that the insurance charges will be $2696.69.\n",
    "\n",
    "The model provides it's input and output schemas through the \"input_schema\" and \"output_schemas\" class attributes. We can view these schemas a JSON schemas by calling the .schema() method on the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f1e2a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelInput',\n",
       " 'description': \"Schema for input of the model's predict method.\",\n",
       " 'type': 'object',\n",
       " 'properties': {'age': {'title': 'Age',\n",
       "   'description': 'Age of primary beneficiary in years.',\n",
       "   'minimum': 18,\n",
       "   'maximum': 65,\n",
       "   'type': 'integer'},\n",
       "  'sex': {'title': 'Sex',\n",
       "   'description': 'Gender of beneficiary.',\n",
       "   'allOf': [{'$ref': '#/definitions/SexEnum'}]},\n",
       "  'bmi': {'title': 'Body Mass Index',\n",
       "   'description': 'Body mass index of beneficiary.',\n",
       "   'minimum': 15.0,\n",
       "   'maximum': 50.0,\n",
       "   'type': 'number'},\n",
       "  'children': {'title': 'Children',\n",
       "   'description': 'Number of children covered by health insurance.',\n",
       "   'minimum': 0,\n",
       "   'maximum': 5,\n",
       "   'type': 'integer'},\n",
       "  'smoker': {'title': 'Smoker',\n",
       "   'description': 'Whether beneficiary is a smoker.',\n",
       "   'type': 'boolean'},\n",
       "  'region': {'title': 'Region',\n",
       "   'description': 'Region where beneficiary lives.',\n",
       "   'allOf': [{'$ref': '#/definitions/RegionEnum'}]}},\n",
       " 'definitions': {'SexEnum': {'title': 'SexEnum',\n",
       "   'description': \"Enumeration for the value of the 'sex' input of the model.\",\n",
       "   'enum': ['male', 'female'],\n",
       "   'type': 'string'},\n",
       "  'RegionEnum': {'title': 'RegionEnum',\n",
       "   'description': \"Enumeration for the value of the 'region' input of the model.\",\n",
       "   'enum': ['southwest', 'southeast', 'northwest', 'northeast'],\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556092eb",
   "metadata": {},
   "source": [
    "The output schema looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab1c9b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelOutput',\n",
       " 'description': \"Schema for output of the model's predict method.\",\n",
       " 'type': 'object',\n",
       " 'properties': {'charges': {'title': 'Charges',\n",
       "   'description': 'Individual medical costs billed by health insurance to customer in US dollars.',\n",
       "   'type': 'number'}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628402f",
   "metadata": {},
   "source": [
    "## Creating the Logging Decorator\n",
    "\n",
    "Now that we have a logging configuration with all of the basics, we'll start working on a Decorator that can help us do logging around an MLModel instance. \n",
    "\n",
    "In order to build a MLModel decorator class, we'll need to inherit from the MLModelDecorator class and add some functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a49868b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import logging\n",
    "from ml_base.decorator import MLModelDecorator\n",
    "from ml_base.ml_model import MLModelSchemaValidationException\n",
    "\n",
    "\n",
    "class LoggingDecorator(MLModelDecorator):\n",
    "    \"\"\"Decorator to do logging around an MLModel instance.\"\"\"\n",
    "\n",
    "    def __init__(self, input_fields: Optional[List[str]] = None, \n",
    "                 output_fields: Optional[List[str]] = None) -> None:\n",
    "        super().__init__(input_fields=input_fields, output_fields=output_fields)\n",
    "        self.__dict__[\"_logger\"] = None\n",
    "        \n",
    "    def predict(self, data):\n",
    "        if self.__dict__[\"_logger\"] is None:\n",
    "            self.__dict__[\"_logger\"] = logging.getLogger(\"{}_{}\".format(\n",
    "                self._model.qualified_name, \"_logger\"))\n",
    "        \n",
    "        # extra fields to be added to the log record\n",
    "        extra = {\n",
    "            \"action\": \"predict\",\n",
    "            \"model_qualified_name\": self._model.qualified_name,\n",
    "            \"model_version\": self._model.version\n",
    "        }\n",
    "        \n",
    "        # adding model input fields to the extra fields to be logged\n",
    "        new_extra = dict(extra)\n",
    "        if self._configuration[\"input_fields\"] is not None:\n",
    "            for input_field in self._configuration[\"input_fields\"]:\n",
    "                new_extra[input_field] = getattr(data, input_field)\n",
    "        \n",
    "        self.__dict__[\"_logger\"].info(\"Prediction requested.\", extra=new_extra)\n",
    "        \n",
    "        try:\n",
    "            prediction = self._model.predict(data=data)\n",
    "            extra[\"status\"] = \"success\"\n",
    "            \n",
    "            # adding model output fields to the extra fields to be logged\n",
    "            new_extra = dict(extra)\n",
    "            if self._configuration[\"output_fields\"] is not None:\n",
    "                for output_field in self._configuration[\"output_fields\"]:\n",
    "                    new_extra[output_field] = getattr(prediction, output_field)            \n",
    "            self.__dict__[\"_logger\"].info(\"Prediction created.\", extra=new_extra) \n",
    "            return prediction\n",
    "        except Exception as e:\n",
    "            extra[\"status\"] = \"error\"\n",
    "            extra[\"error_info\"] = str(e)\n",
    "            self.__dict__[\"_logger\"].error(\"Prediction exception.\", extra=extra)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b35205",
   "metadata": {},
   "source": [
    "The LoggingDecorator class has most of its logic in the predict method. This method simply instantiates a logger object and logs a message before a prediction is made, after it is made, and in the case when an exception is raised. Notice that the exception information is logged, but the exception is re-raised immediately after. We don't want to keep the exception from being handled by whatever code is using the model.\n",
    "\n",
    "The decorator also adds a few fields to the log message:\n",
    "\n",
    "- action: the action that the model is performing, in this case \"prediction\"\n",
    "- model_qualified_name: the qualified name of the model performing the action\n",
    "- model_version: the version of the model performing the action\n",
    "- status: the result of the action, can be either \"success\" or \"error\"\n",
    "- error_info: an optional field that adds error information when an exception is raised\n",
    "\n",
    "These fields are added on top of all the regular fields that the logging package provides. The extra information should allow us to easily filter logs later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60f1e3",
   "metadata": {},
   "source": [
    "## Decorating the Model\n",
    "\n",
    "To test out the decorator weâ€™ll first instantiate the model object that we want to use with the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d6d2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceChargesModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401461a9",
   "metadata": {},
   "source": [
    "Next, weâ€™ll instantiate the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cd1d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_decorator = LoggingDecorator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5950edc",
   "metadata": {},
   "source": [
    "We can add the model instance to the decorator after itâ€™s been instantiated like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4fdd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorated_model = logging_decorator.set_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc37bd0",
   "metadata": {},
   "source": [
    "We can see the decorator and the model objects by printing the reference to the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2463acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoggingDecorator(InsuranceChargesModel)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorated_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa907e",
   "metadata": {},
   "source": [
    "The decorator object is printing out it's own type along with the type of the model that it is decorating.\n",
    "\n",
    "Now we can try out the logging decorator by making a few predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c80c4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 18:09:45,971\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/578892535.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\"}\n",
      "{\"asctime\": \"2022-06-12 18:09:46,016\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/578892535.py\", \"lineno\": 44, \"levelname\": \"INFO\", \"message\": \"Prediction created.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"status\": \"success\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=2696.69)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = decorated_model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d14a7",
   "metadata": {},
   "source": [
    "Calling the predict method on the decorated model now emits two log messages. The first message is a \"Prediction requested.\" message and happens before the model's predict method is called. The second is a \"Prediction created.\" message and happens after the prediction is returned by the model to the decorator. The decorator can also log exceptions made by the model.\n",
    "\n",
    "The logging decorator is also able to grab fields from the model's input and output and log those alongside the other fields. Here is how to configure the logging decorator to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0573e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 18:09:58,567\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/578892535.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"age\": 25, \"bmi\": 21.0}\n",
      "{\"asctime\": \"2022-06-12 18:09:58,611\", \"hostname\": \"Brians-MBP.attlocal.net\", \"node_ip\": \"198.197.196.195\", \"process\": 36023, \"thread\": 4445095424, \"pathname\": \"/var/folders/vb/ym0r3p412kg598rdky_lb5_w0000gn/T/ipykernel_36023/578892535.py\", \"lineno\": 44, \"levelname\": \"INFO\", \"message\": \"Prediction created.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"status\": \"success\", \"charges\": 2696.69}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=2696.69)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging_decorator = LoggingDecorator(input_fields=[\"age\", \"bmi\"],\n",
    "                                     output_fields=[\"charges\"])\n",
    "\n",
    "decorated_model = logging_decorator.set_model(model)\n",
    "\n",
    "prediction = decorated_model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed584261",
   "metadata": {},
   "source": [
    "The \"Prediction requested.\" log message now has two extra fields, the \"age\" field and the \"bmi\" field which were directly copied from the model input. The \"Prediction created.\" log message also has the \"charges\" field, which is the prediction returned by the model.\n",
    "\n",
    "We now have a working logging decorator that can help us to do logging if the model does not do logging for itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e91c47",
   "metadata": {},
   "source": [
    "## Adding the Decorator to a Deployed Model\n",
    "\n",
    "Now that we have a working decorator that works locally, we can deploy it with a model inside of a service. The [rest_model_service package](https://pypi.org/project/rest-model-service/) is able to host ML models and create a RESTful API for each individual model. We don't need to write any code to do this because the service can decorate the models that it hosts with decorators that we provide. You can learn more about the package in [this blog post](https://www.tekhnoal.com/rest-model-service.html).\n",
    "\n",
    "To install the service package, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "910ebd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rest_model_service>=0.3.0\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8c690",
   "metadata": {},
   "source": [
    "The configuration for our model and decorator looks like this:\n",
    "\n",
    "```yaml\n",
    "service_title: Insurance Charges Model Service\n",
    "models:\n",
    "  - qualified_name: insurance_charges_model\n",
    "    class_path: insurance_charges_model.prediction.model.InsuranceChargesModel\n",
    "    create_endpoint: true\n",
    "    decorators:\n",
    "      - class_path: ml_model_logging.logging_decorator.LoggingDecorator\n",
    "logging:\n",
    "    version: 1\n",
    "    disable_existing_loggers: true\n",
    "    formatters:\n",
    "      json_formatter:\n",
    "        class: pythonjsonlogger.jsonlogger.JsonFormatter\n",
    "        format: \"%(asctime)s %(hostname)s %(node_ip)s %(process)s %(thread)s %(pathname)s %(lineno)s %(levelname)s %(message)s\"\n",
    "    filters:\n",
    "      hostname_filter:\n",
    "        \"()\": ml_model_logging.filters.HostnameFilter\n",
    "      environment_info_filter:\n",
    "        \"()\": ml_model_logging.filters.EnvironmentInfoFilter\n",
    "        env_variables:\n",
    "        - NODE_IP\n",
    "    handlers:\n",
    "      stdout:\n",
    "        level: INFO\n",
    "        class: logging.StreamHandler\n",
    "        stream: ext://sys.stdout\n",
    "        formatter: json_formatter\n",
    "        filters:\n",
    "        - hostname_filter\n",
    "        - environment_info_filter\n",
    "    loggers:\n",
    "      root:\n",
    "        level: INFO\n",
    "        handlers:\n",
    "        - stdout\n",
    "        propagate: false\n",
    "```\n",
    "\n",
    "The two main sections in the file are the \"models\" section and the \"logging\" section. The models section is simpler and simply lists the InsuranceChargesModel, along with the LoggingDecorator. This section works in the same way as in previous blog posts. The logging configuration is set up exactly like we set it up is the examples above, the YAML is converted to a dictionary and passed directly into the logging.config.dictConfig() function.\n",
    "\n",
    "To run the service locally, execute these commands:\n",
    "\n",
    "```bash\n",
    "export PYTHONPATH=./\n",
    "export REST_CONFIG=./configuration/rest_configuration.yaml\n",
    "uvicorn rest_model_service.main:app --reload\n",
    "```\n",
    "\n",
    "The service should come up and can be accessed in a web browser at http://127.0.0.1:8000. When you access that URL you will be redirected to the documentation page that is generated by the FastAPI package:\n",
    "\n",
    "![Service Documentation](service_documentation_lfmlm.png)\n",
    "![Service Documentation]({attach}service_documentation_lfmlm.png){ width=100% }\n",
    "\n",
    "The documentation allows you to make requests against the API in order to try it out. Here's a prediction request against the insurance charges model:\n",
    "\n",
    "![Prediction Request](prediction_request_lfmlm.png)\n",
    "![Prediction Request]({attach}prediction_request_lfmlm.png){ width=100% }\n",
    "\n",
    "And the prediction result:\n",
    "\n",
    "![Prediction Response](prediction_response_lfmlm.png)\n",
    "![Prediction Response]({attach}prediction_response_lfmlm.png){ width=100% }\n",
    "\n",
    "\n",
    "The prediction made by the model had to go through the logging decorator that we configured into the service, so we got these two log records from the process:\n",
    "\n",
    "\n",
    "![Prediction Log](prediction_log_lfmlm.png)\n",
    "![Prediction Log]({attach}prediction_log_lfmlm.png){ width=100% }\n",
    "\n",
    "By using the MLModel base class provided by the ml_base package and the REST service framework provided by the rest_model_service package we're able to quickly stand up a service to host the model. The decorator that we want to test can also be added to the model through configuration, including all of its parameters.\n",
    "\n",
    "\n",
    "The local web service process emits the logs to stdout just as we configured it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ad9b7",
   "metadata": {},
   "source": [
    "## Deploying the Model Service\n",
    "\n",
    "Now that we have a working service that is running locally, we can work on deploying it to a cloud provider. We'll be using the [managed Kubernetes service](https://www.digitalocean.com/products/kubernetes) on DigitalOcean to deploy the model service. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41a6b5",
   "metadata": {},
   "source": [
    "### Creating a Docker Image\n",
    "\n",
    "Kubernetes needs to have a Docker image in order to deploy something, we'll build an image using this Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "ARG DATE_CREATED\n",
    "ARG VERSION\n",
    "ARG REVISION\n",
    "\n",
    "LABEL org.opencontainers.image.title=\"Logging for ML Models\"\n",
    "LABEL org.opencontainers.image.description=\"Logging for machine learning models.\"\n",
    "LABEL org.opencontainers.image.created=$DATE_CREATED\n",
    "LABEL org.opencontainers.image.authors=\"6666331+schmidtbri@users.noreply.github.com\"\n",
    "LABEL org.opencontainers.image.source=\"https://github.com/schmidtbri/logging-for-ml-models\"\n",
    "LABEL org.opencontainers.image.version=$VERSION\n",
    "LABEL org.opencontainers.image.revision=$REVISION\n",
    "LABEL org.opencontainers.image.licenses=\"MIT License\"\n",
    "LABEL org.opencontainers.image.base.name=\"python:3.9-slim\"\n",
    "\n",
    "WORKDIR ./service\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get --assume-yes install git\n",
    "\n",
    "COPY ./ml_model_logging ./data_enrichment\n",
    "COPY ./configuration ./configuration\n",
    "COPY ./LICENSE ./LICENSE\n",
    "COPY ./service_requirements.txt ./service_requirements.txt\n",
    "\n",
    "RUN pip install -r service_requirements.txt\n",
    "\n",
    "CMD [\"uvicorn\", \"rest_model_service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\n",
    "```\n",
    "\n",
    "The Dockerfile includes a set of labels from the [Open Containers annotations specification](https://github.com/opencontainers/image-spec/blob/main/annotations.md). Most of the labels are hardcoded in the Dockerfile, but there are three that we need to add from the outside: the date created, the version, and the revision. To do this we'll pull some information into environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fde329ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-06-12 18:11:44']\n",
      "['7f21864be6b0566f7b1883c20e0f6909d4776952']\n"
     ]
    }
   ],
   "source": [
    "DATE_CREATED=!date +\"%Y-%m-%d %T\"\n",
    "# current git revision which is a SHA5 hash\n",
    "REVISION=!git rev-parse HEAD\n",
    "\n",
    "!echo \"$DATE_CREATED\"\n",
    "!echo \"$REVISION\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef141e0",
   "metadata": {},
   "source": [
    "Now we can use the values to build the image. We'll also provide the version as a build argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5644a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build \\\n",
    "  --build-arg DATE_CREATED=\"$DATE_CREATED\" \\\n",
    "  --build-arg VERSION=\"0.1.0\" \\\n",
    "  --build-arg REVISION=\"$REVISION\" \\\n",
    "  -t insurance_charges_model_service:0.1.0 ..\\\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc78b4c",
   "metadata": {},
   "source": [
    "To find the image we just built, we'll search through the local docker images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28b24a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_charges_model_service                                                                   0.1.0     b2445b60123b   2 minutes ago   1.25GB\r\n",
      "registry.digitalocean.com/dev-model-services-container-registry/insurance_charges_model_service   0.1.0     a3624392da83   10 days ago     1.25GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker images | grep insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3c4c1",
   "metadata": {},
   "source": [
    "Next, we'll start the image to see if everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f0dfd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91d91849e46fdde11eeef83f120340cf1071705a9114f6ce9a738c21436a1cf6\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -d \\\n",
    "    -p 8000:8000 \\\n",
    "    -e REST_CONFIG=./configuration/rest_configuration.yaml \\\n",
    "    -e NODE_IP=\"198.197.196.195\" \\\n",
    "    --name insurance_charges_model_service \\\n",
    "    insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208fc7e",
   "metadata": {},
   "source": [
    "Notice that we added an environment variable called NODE_IP, this is just so we have a value to pull into the logs later, its not the real node IP address.\n",
    "\n",
    "The service should be accessible on port 8000 of localhost, so we'll try to make a prediction using the curl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "383b05c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":46277.67}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://127.0.0.1:8000/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d \"{ \\\n",
    "      \\\"age\\\": 65, \\\n",
    "      \\\"sex\\\": \\\"male\\\", \\\n",
    "      \\\"bmi\\\": 50, \\\n",
    "      \\\"children\\\": 5, \\\n",
    "      \\\"smoker\\\": true, \\\n",
    "      \\\"region\\\": \\\"southwest\\\" \\\n",
    "    }\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa9e6",
   "metadata": {},
   "source": [
    "The service is up and running in the docker container. To view the logs coming out of the process, we'll use the docker logs command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9753c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-12 22:17:26,583\", \"hostname\": \"91d91849e46f\", \"node_ip\": \"198.197.196.195\", \"process\": 1, \"thread\": 140681388955456, \"pathname\": \"/usr/local/lib/python3.9/site-packages/rest_model_service/main.py\", \"lineno\": 26, \"levelname\": \"INFO\", \"message\": \"Starting 'Insurance Charges Model Service'.\"}\r\n",
      "/usr/local/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\r\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\r\n",
      "{\"asctime\": \"2022-06-12 22:17:27,924\", \"hostname\": \"91d91849e46f\", \"node_ip\": \"198.197.196.195\", \"process\": 1, \"thread\": 140681388955456, \"pathname\": \"/usr/local/lib/python3.9/site-packages/rest_model_service/main.py\", \"lineno\": 53, \"levelname\": \"INFO\", \"message\": \"Loaded insurance_charges_model model.\"}\r\n",
      "{\"asctime\": \"2022-06-12 22:17:27,925\", \"hostname\": \"91d91849e46f\", \"node_ip\": \"198.197.196.195\", \"process\": 1, \"thread\": 140681388955456, \"pathname\": \"/usr/local/lib/python3.9/site-packages/rest_model_service/main.py\", \"lineno\": 71, \"levelname\": \"INFO\", \"message\": \"Added LoggingDecorator decorator to insurance_charges_model model.\"}\r\n",
      "{\"asctime\": \"2022-06-12 22:17:27,926\", \"hostname\": \"91d91849e46f\", \"node_ip\": \"198.197.196.195\", \"process\": 1, \"thread\": 140681388955456, \"pathname\": \"/usr/local/lib/python3.9/site-packages/rest_model_service/main.py\", \"lineno\": 90, \"levelname\": \"INFO\", \"message\": \"Created endpoint for insurance_charges_model model.\"}\r\n",
      "{\"asctime\": \"2022-06-12 22:17:34,744\", \"hostname\": \"91d91849e46f\", \"node_ip\": \"198.197.196.195\", \"process\": 1, \"thread\": 140680842913536, \"pathname\": \"/service/./ml_model_logging/logging_decorator.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\"}\r\n"
     ]
    }
   ],
   "source": [
    "!docker logs insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879e0cd",
   "metadata": {},
   "source": [
    "As we expected, the logs are coming out in JSON format. We're done with the docker container so we'll stop it and stop it and remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1df19cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_charges_model_service\n",
      "insurance_charges_model_service\n"
     ]
    }
   ],
   "source": [
    "!docker kill insurance_charges_model_service\n",
    "!docker rm insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63af866",
   "metadata": {},
   "source": [
    "### Setting up DigitalOcean\n",
    "\n",
    "To deploy the model to DigitalOcean, we'll need to connect to their API. To interact with the API, we'l be using the DigitalOcean CLI, which is a commmand line tool. Installation instructions for the CLI package are [here](https://docs.digitalocean.com/reference/doctl/how-to/install/). To interact with the API, we'll also need an authentication token, which we can get by following [these instructions](https://docs.digitalocean.com/reference/api/create-personal-access-token/). To add the token to the doctl CLI tool, we execute this command:\n",
    "\n",
    "```bash\n",
    "doctl auth init --context model-services-context\n",
    "```\n",
    "\n",
    "The command asks for the token and saves it for later use.\n",
    "\n",
    "Now that we have the credentials set up, we can start creating the infrastructure for our model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231352a1",
   "metadata": {},
   "source": [
    "### Creating the Kubernetes Cluster\n",
    "\n",
    "Some of the commands in this section will have a lot of output, we we'll be shortening the output to maintain clarity.\n",
    "\n",
    "We wont be creating the managed Kubernetes cluster by hand, we'll be doing it through an Infrastructure as Code tool called [Terraform](https://www.terraform.io/). Terraform will allow us to declaratively state our infrastructure requirements in configuration files, and then create, manage, and destroy it with simple commands. The command line Terraform tool can be installed by following [these intructions](https://learn.hashicorp.com/tutorials/terraform/install-cli). \n",
    "\n",
    "The actual Terraform module that we'll be using is not in the current repository, it's in [a separate repository](https://github.com/schmidtbri/do-kubernetes-cluster). We'll be referencing the Terraform module and adding our own variables to customize the infrastrucutre. Putting the IaC code in a different repository and importing it makes the code reusable in many different contexts.\n",
    "\n",
    "The Terraform code that configures the infrastructure is in the terraform/k8s_cluster.tf file in this repository. The file looks like this:\n",
    "\n",
    "```terraform\n",
    "terraform {\n",
    "  required_providers {\n",
    "    digitalocean = {\n",
    "      source = \"digitalocean/digitalocean\"\n",
    "      version = \"~> 2.0\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "module \"kubernetes_cluster\" {\n",
    "  source = \"github.com/schmidtbri/do-kubernetes-cluster\"\n",
    "\n",
    "  project_name                = \"model-services\"\n",
    "  environment                 = \"dev\"\n",
    "  region                      = \"nyc3\"\n",
    "  default_pool_size           = 2\n",
    "  default_pool_worker_type    = \"s-1vcpu-2gb\"\n",
    "  enable_additional_pool      = true\n",
    "  additional_pool_size        = 2\n",
    "  additional_pool_worker_type = \"s-2vcpu-4gb\"\n",
    "}\n",
    "```\n",
    "\n",
    "The terraform code sets up the DigitalOcean provider at the top, which will be used to interact with the DigitalOcean API. The \"kubernetes_cluter\" module is configured to pull the source from the IaC repository, configuring it to create these resources:\n",
    "\n",
    "- a Digital Ocean project to hold resources\n",
    "- a docker registry\n",
    "- a VPC for the cluster nodes\n",
    "- a kubernetes cluster\n",
    "- an additional node pool within the same cluster\n",
    "\n",
    "The variables are used to customize the resources to our needs. The variables are:\n",
    "\n",
    "- project_name: Name of the project, this name will be added to the names of all of the resources created.\n",
    "- environment: Environment name that will be added to the name of all of the resources created.\n",
    "- region: Geographical region to use for the resources.\n",
    "- default_pool_size: Number of nodes to create in default node pool.\n",
    "- default_pool_worker_type: Type of the droplets to use for the default node pool.\t\n",
    "- enable_additional_pool: Enable or disable creation of additional node pool.\t\n",
    "- additional_pool_size: Number of nodes to create in the additional node pool.\t\n",
    "- additional_pool_worker_type: Type of the droplets to use for the additional node pool.\t\n",
    "\n",
    "We'll be creating a cluster for hosting model services and we want to create a development environment to experiment in. We'll be creating two node pools because we want to run extra workloads that we want to keep separate from the model service deployments. The default node pool will have two nodes, and the additional node pool will also have two nodes.\n",
    "\n",
    "To create the resources we'll need to apply the module. First we'll change into the terraform folder and save the DigitalOcean token as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8651fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../terraform\n",
    "\n",
    "%env DIGITALOCEAN_TOKEN=dop_v1_4e7db92644ece702e39f628ba4c5348c55ae57de845de5fc2e55765823ba5263\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc756caf",
   "metadata": {},
   "source": [
    "Next, we'll initialize the Terraform environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b42f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "- Reusing previous version of digitalocean/digitalocean from the dependency lock file\n",
      "- Using previously-installed digitalocean/digitalocean v2.20.0\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!terraform init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01760ef9",
   "metadata": {},
   "source": [
    "The Terraform CLI tool has downloaded the necessary provider code and started the environment. In order to deploy infrastructure, we'll first need to make a plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f65d8d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Terraform used the selected providers to generate the following execution plan.\r\n",
      "Resource actions are indicated with the following symbols:\r\n",
      "  \u001b[32m+\u001b[0m create\r\n",
      "\u001b[0m\r\n",
      "Terraform will perform the following actions:\r\n",
      "\r\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_container_registry.container_registry\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_container_registry\" \"container_registry\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m               = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                     = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m                   = \"dev-model-services-container-registry\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m                 = \"nyc3\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mserver_url\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstorage_usage_bytes\u001b[0m\u001b[0m    = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msubscription_tier_slug\u001b[0m\u001b[0m = \"basic\"\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_cluster\" \"cluster\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_upgrade\u001b[0m\u001b[0m   = true\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_subnet\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m     = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m       = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mha\u001b[0m\u001b[0m             = false\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mipv4_address\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mkube_config\u001b[0m\u001b[0m    = (sensitive value)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m           = \"dev-model-services-cluster\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m         = \"nyc3\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mservice_subnet\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstatus\u001b[0m\u001b[0m         = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msurge_upgrade\u001b[0m\u001b[0m  = true\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m     = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m            = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mversion\u001b[0m\u001b[0m        = \"1.22.8-do.1\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mvpc_uuid\u001b[0m\u001b[0m       = (known after apply)\r\n",
      "\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0mmaintenance_policy {\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mday\u001b[0m\u001b[0m        = \"sunday\"\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mduration\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstart_time\u001b[0m\u001b[0m = \"04:00\"\r\n",
      "        }\r\n",
      "\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0mnode_pool {\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"dev-model-services-default-worker-pool\"\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 2\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-1vcpu-2gb\"\r\n",
      "        }\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_node_pool\" \"additional_pool\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_id\u001b[0m\u001b[0m        = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"dev-model-services-additional-pool\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 2\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-2vcpu-4gb\"\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_project.project\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_project\" \"project\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mis_default\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"dev-model-services\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mowner_id\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mowner_uuid\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mpurpose\u001b[0m\u001b[0m    = \"Web Application\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mresources\u001b[0m\u001b[0m  = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m = (known after apply)\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_vpc.cluster_vpc\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_vpc\" \"cluster_vpc\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdefault\u001b[0m\u001b[0m    = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mip_range\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"dev-model-services-vpc\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m     = \"nyc3\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m        = (known after apply)\r\n",
      "\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0mtimeouts {\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdelete\u001b[0m\u001b[0m = \"10m\"\r\n",
      "        }\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mPlan:\u001b[0m 5 to add, 0 to change, 0 to destroy.\r\n",
      "\u001b[0m\u001b[90m\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\r\n",
      "\r\n",
      "Saved the plan to: tfplan\r\n",
      "\r\n",
      "To perform exactly these actions, run the following command to apply:\r\n",
      "    terraform apply \"tfplan\"\r\n"
     ]
    }
   ],
   "source": [
    "!terraform plan -out=tfplan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fa299",
   "metadata": {},
   "source": [
    "As we expected, there will be five resources created. To create the resources, we'll use the apply terraform command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "facb38a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_container_registry.container_registry: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Creation complete after 1s [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_container_registry.container_registry: Creation complete after 7s [id=dev-model-services-container-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [1m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [1m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [1m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [1m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [1m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [1m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [2m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [2m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [2m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [2m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [2m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [2m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [3m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [3m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [3m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [3m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [3m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [3m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [4m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [4m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [4m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [4m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [4m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [4m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [5m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [5m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [5m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Still creating... [5m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Creation complete after 5m32s [id=cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_project.project: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_project.project: Creation complete after 5s [id=a4470669-8c90-468a-9bdb-5e3a27428eff]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [1m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [1m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [1m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [1m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [1m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [1m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [2m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still creating... [2m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Creation complete after 2m12s [id=0734e25f-54da-465d-a6ca-833678b6b067]\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 5 added, 0 changed, 0 destroyed.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!terraform apply -auto-approve tfplan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc0521",
   "metadata": {},
   "source": [
    "The cluster is now ready for use. To push workloads to the cluster we'll need to upload Docker images to the registry and then access them from the cluster. To enable access to the registry from the cluster, we'll use another doctl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c9e28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!doctl kubernetes cluster registry add dev-model-services-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffe9ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/logging-for-ml-models\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f205a0d",
   "metadata": {},
   "source": [
    "### Pushing the Image\n",
    "\n",
    "We've built a Docker image and created a cluster to deploy it to, but we still need to upload the image to the registry so that we can pull it from the cluster. To login to the registry we can use a doctl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05329738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Docker in to registry.digitalocean.com\r\n"
     ]
    }
   ],
   "source": [
    "!doctl registry login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf159a6",
   "metadata": {},
   "source": [
    "The image exists in the local Docker registry, so we'll need to tag it with the remote registry name to upload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "396a68db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag insurance_charges_model_service:0.1.0 registry.digitalocean.com/dev-model-services-container-registry/insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423d88f",
   "metadata": {},
   "source": [
    "Now we can push the image to the DigitalOcean docker registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb9355e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [registry.digitalocean.com/dev-model-services-container-registry/insurance_charges_model_service]\n",
      "\n",
      "\u001b[1Baff73edb: Preparing \n",
      "\u001b[1B67322c6f: Preparing \n",
      "\u001b[1B6a3c9a87: Preparing \n",
      "\u001b[1B90be6b9a: Preparing \n",
      "\u001b[1Bf8a5a5e9: Preparing \n",
      "\u001b[1Bd31b029e: Preparing \n",
      "\u001b[1B93bba98e: Preparing \n",
      "\u001b[1Bb9285d50: Preparing \n",
      "\u001b[1B5ff75c19: Preparing \n",
      "\u001b[1B6adc64fd: Preparing \n",
      "\u001b[1B3e0df215: Preparing \n",
      "\u001b[1B341968bc: Preparing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[13Bff73edb: Pushing  310.5MB/1.023GB\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[2A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KPushing  36.32MB/80.41MB\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[13Bff73edb: Pushing  916.5MB/1.023GB\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[13Bff73edb: Pushed   1.034GB/1.023GB\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K0.1.0: digest: sha256:f46ab89590a6ffd933c8d32935a1c7c21959a93c1288c3f839d6d32de0be361c size: 3045\n"
     ]
    }
   ],
   "source": [
    "!docker push registry.digitalocean.com/dev-model-services-container-registry/insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff99a78",
   "metadata": {},
   "source": [
    "### Accessing the Kubernetes Cluster\n",
    "\n",
    "Now that we have a running cluster, we can connect to it by setting up the kubectl command line tool. The DigitalOcean CLI tool can do this for us with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a007c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mNotice\u001b[0m: Adding cluster credentials to kubeconfig file found in \"/Users/brian/.kube/config\"\r\n",
      "\u001b[32mNotice\u001b[0m: Setting current-context to do-nyc3-dev-model-services-cluster\r\n"
     ]
    }
   ],
   "source": [
    "!doctl kubernetes cluster kubeconfig save cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ddf23",
   "metadata": {},
   "source": [
    "The unique identifier is for the cluster that was just created, we can get it through the DigitalOcean console. When the command finishes, the current kubectl context should be switched to the newly created cluster.\n",
    "\n",
    "To make sure everything is working we can get a list of the nodes in the cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f275cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                           STATUS   ROLES    AGE    VERSION\r\n",
      "dev-model-services-additional-pool-c2s5n       Ready    <none>   119m   v1.22.8\r\n",
      "dev-model-services-additional-pool-c2ss9       Ready    <none>   119m   v1.22.8\r\n",
      "dev-model-services-default-worker-pool-c2spi   Ready    <none>   122m   v1.22.8\r\n",
      "dev-model-services-default-worker-pool-c2spv   Ready    <none>   123m   v1.22.8\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d68ebe",
   "metadata": {},
   "source": [
    "As we expected, we have four nodes, two in each node pool. We'll be using [node tags](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/) to do scheduling later, so we'll look the node tags up like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "666db08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                           STATUS   ROLES    AGE    VERSION   LABELS\r\n",
      "dev-model-services-additional-pool-c2s5n       Ready    <none>   119m   v1.22.8   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=s-2vcpu-4gb,beta.kubernetes.io/os=linux,doks.digitalocean.com/node-id=9c522467-1824-444d-8e5a-8696ffcb8ac2,doks.digitalocean.com/node-pool-id=0734e25f-54da-465d-a6ca-833678b6b067,doks.digitalocean.com/node-pool=dev-model-services-additional-pool,doks.digitalocean.com/version=1.22.8-do.1,failure-domain.beta.kubernetes.io/region=nyc3,kubernetes.io/arch=amd64,kubernetes.io/hostname=dev-model-services-additional-pool-c2s5n,kubernetes.io/os=linux,node.kubernetes.io/instance-type=s-2vcpu-4gb,region=nyc3,topology.kubernetes.io/region=nyc3\r\n",
      "dev-model-services-additional-pool-c2ss9       Ready    <none>   119m   v1.22.8   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=s-2vcpu-4gb,beta.kubernetes.io/os=linux,doks.digitalocean.com/node-id=96963518-6e45-4839-8829-a4ef4854e043,doks.digitalocean.com/node-pool-id=0734e25f-54da-465d-a6ca-833678b6b067,doks.digitalocean.com/node-pool=dev-model-services-additional-pool,doks.digitalocean.com/version=1.22.8-do.1,failure-domain.beta.kubernetes.io/region=nyc3,kubernetes.io/arch=amd64,kubernetes.io/hostname=dev-model-services-additional-pool-c2ss9,kubernetes.io/os=linux,node.kubernetes.io/instance-type=s-2vcpu-4gb,region=nyc3,topology.kubernetes.io/region=nyc3\r\n",
      "dev-model-services-default-worker-pool-c2spi   Ready    <none>   123m   v1.22.8   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=s-1vcpu-2gb,beta.kubernetes.io/os=linux,doks.digitalocean.com/node-id=866ada4d-aa24-425e-9949-d7a1ba5aefc7,doks.digitalocean.com/node-pool-id=0a6d2c5d-a5be-424d-be43-bce66aa9e547,doks.digitalocean.com/node-pool=dev-model-services-default-worker-pool,doks.digitalocean.com/version=1.22.8-do.1,failure-domain.beta.kubernetes.io/region=nyc3,kubernetes.io/arch=amd64,kubernetes.io/hostname=dev-model-services-default-worker-pool-c2spi,kubernetes.io/os=linux,node.kubernetes.io/instance-type=s-1vcpu-2gb,region=nyc3,topology.kubernetes.io/region=nyc3\r\n",
      "dev-model-services-default-worker-pool-c2spv   Ready    <none>   123m   v1.22.8   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=s-1vcpu-2gb,beta.kubernetes.io/os=linux,doks.digitalocean.com/node-id=2cd36dab-f681-43e6-bc7b-9529d51d6f81,doks.digitalocean.com/node-pool-id=0a6d2c5d-a5be-424d-be43-bce66aa9e547,doks.digitalocean.com/node-pool=dev-model-services-default-worker-pool,doks.digitalocean.com/version=1.22.8-do.1,failure-domain.beta.kubernetes.io/region=nyc3,kubernetes.io/arch=amd64,kubernetes.io/hostname=dev-model-services-default-worker-pool-c2spv,kubernetes.io/os=linux,node.kubernetes.io/instance-type=s-1vcpu-2gb,region=nyc3,topology.kubernetes.io/region=nyc3\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes --show-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a73bf",
   "metadata": {},
   "source": [
    "The output is long so we trimmed it down to a single node. We can see a lot of information about a node through the tags that it has. For example, the label \"beta.kubernetes.io/arch=amd64\" tells us the architecture of the node, the label \"doks.digitalocean.com/version=1.22.8-do.1\" tells us the kubernetes version installed. We're most interested in the \"doks.digitalocean.com/node-pool=dev-model-services-additional-pool\" label which tells us which node pool the node belongs to. We'll be using this later to schedule workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bf08c",
   "metadata": {},
   "source": [
    "### Creating a Kubernetes Namespace\n",
    "\n",
    "Now that we have a cluster and are connected to it, we'll create a namespace to hold the resources for our model deployment. The resource definition is in the kubernetes/namespace.yaml file. To apply the manifest to the cluster, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7d2052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): error when creating \"kubernetes/namespace.yaml\": namespaces \"model-services\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f kubernetes/namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a64f4",
   "metadata": {},
   "source": [
    "To take a look at the namespaces, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d93a5337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS   AGE\r\n",
      "default           Active   128m\r\n",
      "kube-node-lease   Active   128m\r\n",
      "kube-public       Active   128m\r\n",
      "kube-system       Active   128m\r\n",
      "model-services    Active   11s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0a472",
   "metadata": {},
   "source": [
    "The new namespace should appear in the listing along with other namespaces created by default by the system. To set the namespace as the default one for all kubectl commands, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0532672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"do-nyc3-dev-model-services-cluster\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context --current --namespace=model-services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e92982",
   "metadata": {},
   "source": [
    "### Creating the Model Service\n",
    "\n",
    "To create the model service we need two types of kubernetes resources, these are:\n",
    "\n",
    "- Deployment: a declarative way to manage a set of pods, the model service pods are managed through the Deployment.\n",
    "- Service: a way to expose a set of pods in a Deployment, the model services is made available to the outside world through the Service, the service type is LoadBalancer which means that a load balancer will be created for the service.\n",
    "\n",
    "Both of these resources are defined in the kubernetes/model_service.yaml file, the file is long so we won't list it here. The env section in the containers definition in the Deployment has a special section which is allowing us to access information about the pod and the node:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "env:\n",
    "  # environment variable pointing at the configuration file to use\n",
    "  - name: REST_CONFIG\n",
    "    value: ./configuration/rest_configuration2.yaml\n",
    "  # environment variables with downward API information\n",
    "  - name: POD_NAME\n",
    "      valueFrom:\n",
    "        fieldRef:\n",
    "          fieldPath: metadata.name\n",
    "  - name: NODE_NAME\n",
    "    valueFrom:\n",
    "      fieldRef:\n",
    "        fieldPath: spec.nodeName\n",
    "...\n",
    "```\n",
    "\n",
    "The pod definition is using the [downward API provided by Kubernetes](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/) to access the node name and the pod name. This information is made available as environment variables. We'll be adding this information to the log by adding the names of the environment variables to the logger configuration that we'll give to the model service. We built a logging context class above for the purpose of adding environment variables to log records.\n",
    "\n",
    "Another section of the Deployment definition is the nodeSelector section:\n",
    "\n",
    "```yaml\n",
    "nodeSelector:\n",
    "  doks.digitalocean.com/node-pool: \"dev-model-services-default-worker-pool\"\n",
    "```\n",
    "\n",
    "The nodeSelector section is making sure that the service pods are going to be scheduled on the default worker pool. We're choosing to schedule the service pods on this node pool so that we can keep the workload separate from the logging system, which we'll be working on later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146dda82",
   "metadata": {},
   "source": [
    "The service is deployed to the Kubernetes cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9fd4dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/insurance-charges-model-deployment configured\n",
      "service/insurance-charges-model-service unchanged\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad273498",
   "metadata": {},
   "source": [
    "The deployment and service for the model service were created together. You can see the new service with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d680ae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE\r\n",
      "insurance-charges-model-service   LoadBalancer   10.245.24.248   138.197.51.107   80:30890/TCP   75m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be82f27",
   "metadata": {},
   "source": [
    "You can also view the pods that are running the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "aa3e77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                  READY   STATUS    RESTARTS   AGE\r\n",
      "insurance-charges-model-deployment-79c64f6f46-m6kkf   1/1     Running   0          7s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l app=insurance-charges-model-service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc14f0",
   "metadata": {},
   "source": [
    "The Service type is LoadBalancer, which means that the cloud provider is providing a load balancer and public IP address through which we can contact the service. To view details about the load balancer provided by DigitalOcean for this Service, we'll execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "94463ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoadBalancer Ingress:     138.197.51.107\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe service insurance-charges-model-service | grep \"LoadBalancer Ingress\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa8341",
   "metadata": {},
   "source": [
    "The load balancer can take a while longer than the service to come up, until the load balancer is running the command won't return anything. The IP address that the DigitalOcean load balancer sits behind will be listed in the output of the command.\n",
    "\n",
    "To make a prediction, we'll hit the IP service with a request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3ff90ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":46277.67,\"prediction_id\":\"8c19b7fe-ee69-46f4-90bd-9ff1c8908bf7\"}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://138.197.51.107/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d \"{ \\\n",
    "      \\\"age\\\": 65, \\\n",
    "      \\\"sex\\\": \\\"male\\\", \\\n",
    "      \\\"bmi\\\": 50, \\\n",
    "      \\\"children\\\": 5, \\\n",
    "      \\\"smoker\\\": true, \\\n",
    "      \\\"region\\\": \\\"southwest\\\" \\\n",
    "    }\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5289bda0",
   "metadata": {},
   "source": [
    "The model service is up and running and returning predictions!\n",
    "\n",
    "We can check which node the pods are scheduled on by describing one of the pods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3ebf0994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-Selectors:              doks.digitalocean.com/node-pool=dev-model-services-default-worker-pool\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pod insurance-charges-model-deployment-79c64f6f46-m6kkf  | grep \"Node-Selectors\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3d7c4",
   "metadata": {},
   "source": [
    "The pod was scheduled on the default worker pool, as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae461e9c",
   "metadata": {},
   "source": [
    "### Accessing the Logs\n",
    "\n",
    "Kubernetes has a built-in system that receives the stdout and stderr outputs of the running containers and saves them to the hard drive of the node for a limited time. You can view the logs emmitted by the containers by using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9be87a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-13 01:57:22,641\", \"hostname\": \"insurance-charges-model-deployment-79c64f6f46-m6kkf\", \"pod_name\": \"insurance-charges-model-deployment-79c64f6f46-m6kkf\", \"node_name\": \"dev-model-services-default-worker-pool-c2spi\", \"process\": 1, \"thread\": 140424458041088, \"pathname\": \"/service/./ml_model_logging/logging_decorator.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"prediction_id\": null}\r\n",
      "{\"asctime\": \"2022-06-13 01:57:22,716\", \"hostname\": \"insurance-charges-model-deployment-79c64f6f46-m6kkf\", \"pod_name\": \"insurance-charges-model-deployment-79c64f6f46-m6kkf\", \"node_name\": \"dev-model-services-default-worker-pool-c2spi\", \"process\": 1, \"thread\": 140424458041088, \"pathname\": \"/service/./ml_model_logging/logging_decorator.py\", \"lineno\": 44, \"levelname\": \"INFO\", \"message\": \"Prediction created.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"status\": \"success\", \"prediction_id\": \"8c19b7fe-ee69-46f4-90bd-9ff1c8908bf7\"}\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs insurance-charges-model-deployment-79c64f6f46-m6kkf  | grep \"\\\"action\\\": \\\"predict\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0ccc1",
   "metadata": {},
   "source": [
    "The logs contain every field that we configured and they are in JSON format, as we expected. The log records also contain the pod_name and node_name fields that we added through the downward API.\n",
    "\n",
    "Although we can view the logs like this, this is not the ideal way to hold logs. We need to be able to search through the logs generated across the whole system. To do this we'll need to export the logs to an external logging system. We'll be working on that in another section of this blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f91695",
   "metadata": {},
   "source": [
    "### Adding a Prediction ID\n",
    "\n",
    "Now that we have a working logging decorator, we'll add one more field to the logs that it produces. We want to be able to uniquely identify each prediction made by the model within the logs, and also to be able to provide a unique identifier for a prediction to clients of the model service. This allows us to quickly debug problems with individual predictions. \n",
    "\n",
    "We built a prediction ID decorator is [a previous blog post](https://www.tekhnoal.com/ml-model-decorators.html). We'll reuse this decorator to add a prediction_id field to the model's input and output. The code is in the current repository in the ml_model_logging/prediction_id_decorator.py file.\n",
    "\n",
    "To add the prediction id decorator to the model, all we need to do is add it to the service configuration file in the decorators section:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "decorators:\n",
    "  - class_path: ml_model_logging.prediction_id_decorator.PredictionIDDecorator\n",
    "  - class_path: ml_model_logging.logging_decorator.LoggingDecorator\n",
    "    configuration:\n",
    "      input_fields: [\"prediction_id\"]\n",
    "      output_fields: [\"prediction_id\"]\n",
    "...\n",
    "```\n",
    "\n",
    "The PredictionIDDecorator class implements the functionality, we wont do a deep dive here because it would make the blog post too long. The decorator is instantiated by the model service and added last to the model, so that a prediction ID is generated before the LoggingDecorator sees the input data.\n",
    "\n",
    "The LoggingDecorator is then configured to log the prediction_id field that is created by the PredictionIDDecorator instance. It's also configured to log the prediction_id from the output of the model because the decorator will generate an id if the client does not provide one.\n",
    "\n",
    "To apply the new configuration, we'll change the kubernetes Deployment and by changing the environment variable that points at the configuration file that the model service is using:\n",
    "\n",
    "```yaml\n",
    "env:\n",
    "  # environment variable pointing at the configuration file to use\n",
    "  - name: REST_CONFIG\n",
    "    value: ./configuration/rest_configuration3.yaml\n",
    "```\n",
    "\n",
    "Now we can modify the Deployment in the cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5045ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/insurance-charges-model-deployment created\n",
      "service/insurance-charges-model-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ec6dce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                  READY   STATUS    RESTARTS      AGE\r\n",
      "elasticsearch-master-0                                1/1     Running   0             48m\r\n",
      "elasticsearch-master-1                                1/1     Running   0             48m\r\n",
      "insurance-charges-model-deployment-79c64f6f46-pt9g2   1/1     Running   0             9s\r\n",
      "kibana-kibana-9d8cfff9c-xlksr                         1/1     Running   1 (32m ago)   38m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67946255",
   "metadata": {},
   "source": [
    "The model service Deployment gets recreated with a different value in the REST_CONFIG environment variable. Now when we make a prediction with the service, we'll get a prediction id in the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "94f794ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":46277.67,\"prediction_id\":\"cfd6006b-69e8-4aac-a6bc-4be5500f336f\"}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://138.197.51.107/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d \"{ \\\n",
    "      \\\"age\\\": 65, \\\n",
    "      \\\"sex\\\": \\\"male\\\", \\\n",
    "      \\\"bmi\\\": 50, \\\n",
    "      \\\"children\\\": 5, \\\n",
    "      \\\"smoker\\\": true, \\\n",
    "      \\\"region\\\": \\\"southwest\\\" \\\n",
    "    }\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4200bd6",
   "metadata": {},
   "source": [
    "Since we did not provide a prediction_id input for the model, the PredictionIDDecorator instance generated one and returned it along with the prediction. Now we can look into the logs to see if the prediction_id field made it into the log records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3d4d63f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2022-06-13 01:05:08,291\", \"hostname\": \"insurance-charges-model-deployment-cf9f7c767-fsmzz\", \"pod_name\": \"insurance-charges-model-deployment-cf9f7c767-fsmzz\", \"node_name\": \"dev-model-services-default-worker-pool-c2spv\", \"process\": 1, \"thread\": 140558518556416, \"pathname\": \"/service/./ml_model_logging/logging_decorator.py\", \"lineno\": 33, \"levelname\": \"INFO\", \"message\": \"Prediction requested.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"prediction_id\": null}\r\n",
      "{\"asctime\": \"2022-06-13 01:05:08,402\", \"hostname\": \"insurance-charges-model-deployment-cf9f7c767-fsmzz\", \"pod_name\": \"insurance-charges-model-deployment-cf9f7c767-fsmzz\", \"node_name\": \"dev-model-services-default-worker-pool-c2spv\", \"process\": 1, \"thread\": 140558518556416, \"pathname\": \"/service/./ml_model_logging/logging_decorator.py\", \"lineno\": 44, \"levelname\": \"INFO\", \"message\": \"Prediction created.\", \"action\": \"predict\", \"model_qualified_name\": \"insurance_charges_model\", \"model_version\": \"0.1.0\", \"status\": \"success\", \"prediction_id\": \"cfd6006b-69e8-4aac-a6bc-4be5500f336f\"}\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs insurance-charges-model-deployment-cf9f7c767-fsmzz | grep \"\\\"action\\\": \\\"predict\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb481889",
   "metadata": {},
   "source": [
    "The logs now have a prediction_id field that matches the value that was generated by the PredictionIDDecorator instance working in the model service. \n",
    "\n",
    "By building some flexibility into the code, we were able to add a prediction ID to the model by using a decorator. We were also able to add the prediction ID to the logs emitted by the logging decorator by configuring it. Lastly, we were able to add the prediction ID decorator to the model service by adding configuration to the model service.\n",
    "\n",
    "The most poweful aspect of this is that we did not need to modify the code of the model, or the code of the decorators, or the code of the model service at all to add this extra field to the model and the logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5254fc",
   "metadata": {},
   "source": [
    "## Creating the Logging System\n",
    "\n",
    "The complexity of modern cloud environment makes it hard to manage logs in individual servers since we really don't know where our workloads are going to be scheduled ahead of time. Kubernetes workloads are also highly distributed, meaning that an application can be replicated in many different nodes in a cluster. This makes it necessary to gather logs together in one place so that we can more easily view and analyze them.\n",
    "\n",
    "A logging system is responsible for gathering  log records from all of the instances of a running application and make them searchable from one centralized location. In this section, we'll add such a logging system to the cluster and use it to monitor the model service we've deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398d8c7",
   "metadata": {},
   "source": [
    "### Logging in Kubernetes\n",
    "\n",
    "Kubernetes is able to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae8178",
   "metadata": {},
   "source": [
    "### Creating a Namespace\n",
    "\n",
    "To begin building the logging system, we'll create a Kubernetes namespace for the system so we can keep thing separate from the rest of the workloads we'll be running in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a7b93dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/logging-system created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f kubernetes/logging_namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192bab6",
   "metadata": {},
   "source": [
    "The namespace is called \"logging-system\". \n",
    "\n",
    "Next we'll switch the kubectl context so that we'll be working exclusively within this namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5942eb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"do-nyc3-dev-model-services-cluster\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context --current --namespace=logging-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e50523",
   "metadata": {},
   "source": [
    "### Installing the Helm Charts\n",
    "\n",
    "All of the services we'll be installing in this section are available as [Helm charts](https://helm.sh/) from [this](https://github.com/elastic/helm-charts) open source repository. We can add the Helm repository with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1313bc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"elastic\" already exists with the same configuration, skipping\r\n"
     ]
    }
   ],
   "source": [
    "!helm repo add elastic https://helm.elastic.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842d4bb",
   "metadata": {},
   "source": [
    "The \"elastic\" repository contains several charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "842dad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     \tCHART VERSION\tAPP VERSION\tDESCRIPTION                                       \r\n",
      "elastic/elasticsearch    \t7.17.3       \t7.17.3     \tOfficial Elastic helm chart for Elasticsearch     \r\n",
      "elastic/apm-server       \t7.17.3       \t7.17.3     \tOfficial Elastic helm chart for Elastic APM Server\r\n",
      "elastic/eck-operator     \t2.2.0        \t2.2.0      \tA Helm chart for deploying the Elastic Cloud on...\r\n",
      "elastic/eck-operator-crds\t2.2.0        \t2.2.0      \tA Helm chart for installing the ECK operator Cu...\r\n",
      "elastic/filebeat         \t7.17.3       \t7.17.3     \tOfficial Elastic helm chart for Filebeat          \r\n",
      "elastic/kibana           \t7.17.3       \t7.17.3     \tOfficial Elastic helm chart for Kibana            \r\n",
      "elastic/logstash         \t7.17.3       \t7.17.3     \tOfficial Elastic helm chart for Logstash          \r\n",
      "elastic/metricbeat       \t7.17.3       \t7.17.3     \tOfficial Elastic helm chart for Metricbeat        \r\n"
     ]
    }
   ],
   "source": [
    "!helm search repo elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b258a",
   "metadata": {},
   "source": [
    "We'll be using these charts:\n",
    "\n",
    "- elastic/filebeat\n",
    "- elastic/logstash\n",
    "- elastic/elasticsearch\n",
    "- elastic/kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2d4b8",
   "metadata": {},
   "source": [
    "### Creating the Log Storage Service\n",
    "\n",
    "The log aggregator needs to have a place to store the logs, to do this we'll use  [ElasticSearch](https://www.elastic.co/elasticsearch/). ElasticSearch is a distributed full-text search enginer with a RESTful API.  The ElasticSearch service is ideal for our needs because our logs are made up of text strings.\n",
    "\n",
    "To install ElasticSearch, we'll provide the ./helm/elasticsearch_values.yaml file to Helm using the elastic/elasticsearch chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eff71a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: elasticsearch\r\n",
      "LAST DEPLOYED: Sun Jun 12 21:07:18 2022\r\n",
      "NAMESPACE: logging-system\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "NOTES:\r\n",
      "1. Watch all cluster members come up.\r\n",
      "  $ kubectl get pods --namespace=logging-system -l app=elasticsearch-master -w2. Test cluster health using Helm test.\r\n",
      "  $ helm --namespace=logging-system test elasticsearch\r\n"
     ]
    }
   ],
   "source": [
    "!helm install elasticsearch elastic/elasticsearch -f ./helm/elasticsearch_values.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933cea88",
   "metadata": {},
   "source": [
    "Now we can view the pods running the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "abfc481e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     READY   STATUS    RESTARTS   AGE\r\n",
      "elasticsearch-master-0   1/1     Running   0          5m46s\r\n",
      "elasticsearch-master-1   1/1     Running   0          5m46s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l app=elasticsearch-master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89b59a",
   "metadata": {},
   "source": [
    "ElasticSearch also has a [Service](https://kubernetes.io/docs/concepts/services-networking/service/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cc14f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE\r\n",
      "elasticsearch-master            ClusterIP   10.245.219.122   <none>        9200/TCP,9300/TCP   5m53s\r\n",
      "elasticsearch-master-headless   ClusterIP   None             <none>        9200/TCP,9300/TCP   5m53s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc3ced",
   "metadata": {},
   "source": [
    "ElasticSearch is deployed as a [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/), which is a way to schedule workloads on Kubernetes that need to maintain state. \n",
    "\n",
    "The StatefulSet is also running on the additional node pool. We did this by adding a nodeSelector to the Helm values file:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "nodeSelector:\n",
    "    doks.digitalocean.com/node-pool: \"dev-model-services-additional-pool\"\n",
    "...\n",
    "```\n",
    "\n",
    "This scheduling requirement will prevent us from running the logging system on the same nodes as the model service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a11389",
   "metadata": {},
   "source": [
    "### Creating the Log User Interface Service\n",
    "\n",
    "To view the logs we'll be using [Kibana](https://www.elastic.co/kibana/). Kibana is a web application that can provide access to and visualize logs stored in ElasticSearch.\n",
    "\n",
    "To install Kibana, we'll provide the ./helm/kibana_values.yaml file to Helm using the elastic/kibana chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5c6f3a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: kibana\r\n",
      "LAST DEPLOYED: Sun Jun 12 21:18:03 2022\r\n",
      "NAMESPACE: logging-system\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "TEST SUITE: None\r\n"
     ]
    }
   ],
   "source": [
    "!helm install kibana elastic/kibana -f ./helm/kibana_values.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f3278d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            READY   STATUS    RESTARTS        AGE\r\n",
      "kibana-kibana-9d8cfff9c-xlksr   1/1     Running   1 (5m34s ago)   11m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l app=kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6976cbc",
   "metadata": {},
   "source": [
    "Kibana is deployed as a normal web service. We can view the Kibana service like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d34fc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kibana-kibana                   ClusterIP   10.245.52.191    <none>        5601/TCP            11m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services | grep \"kibana\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68966e",
   "metadata": {},
   "source": [
    "Te Kibana pods are also scheduled on the additional node pool using a nodeSelector:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "nodeSelector:\n",
    "  doks.digitalocean.com/node-pool: \"dev-model-services-additional-pool\"\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f428f9",
   "metadata": {},
   "source": [
    "To access the Kibana web UI, we'll forward the port from the pod to a local port:\n",
    "\n",
    "```bash\n",
    "kubectl port-forward svc/kibana-kibana 5601:5601\n",
    "```\n",
    "\n",
    "We can view the Kibana UI on a local browser:\n",
    "\n",
    "![Kibana UI](kibana_ui.png)\n",
    "![Kibana UI]({attach}kibana_ui.png){ width=100% }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162a45f",
   "metadata": {},
   "source": [
    "### Creating the Log Aggregator Service\n",
    "\n",
    "Once the logs have been forwarded from the individual nodes in the cluster, we'll need to aggregated them and store them somewhere. To aggregate the logs, we'll use [Logstash](https://www.elastic.co/logstash/). Logstash is able to ingest data from many sources, process it, and save it to a destination.\n",
    "\n",
    "To install Logstash, we'll provide the ./helm/logstash_values.yaml file to Helm using the elastic/logstash chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "28b3313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: logstash\r\n",
      "LAST DEPLOYED: Sun Jun 12 22:04:59 2022\r\n",
      "NAMESPACE: logging-system\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "TEST SUITE: None\r\n",
      "NOTES:\r\n",
      "1. Watch all cluster members come up.\r\n",
      "  $ kubectl get pods --namespace=logging-system -l app=logstash-logstash -w\r\n"
     ]
    }
   ],
   "source": [
    "!helm install logstash elastic/logstash -f ./helm/logstash_values.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14325ec",
   "metadata": {},
   "source": [
    "We can view the pods that are running the Logstash service like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e331eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  READY   STATUS    RESTARTS   AGE\r\n",
      "logstash-logstash-0   0/1     Running   0          88s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l app=logstash-logstash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f67b2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         logstash-logstash-0\r\n",
      "Namespace:    logging-system\r\n",
      "Priority:     0\r\n",
      "Node:         dev-model-services-additional-pool-c2ss9/10.108.16.5\r\n",
      "Start Time:   Sun, 12 Jun 2022 22:05:01 -0400\r\n",
      "Labels:       app=logstash-logstash\r\n",
      "              chart=logstash\r\n",
      "              controller-revision-hash=logstash-logstash-65c4bdd744\r\n",
      "              heritage=Helm\r\n",
      "              release=logstash\r\n",
      "              statefulset.kubernetes.io/pod-name=logstash-logstash-0\r\n",
      "Annotations:  pipelinechecksum: 4839e081dd1fb1ef4e11ac386773fc6fbb9af9e4be1ff574f51527138017016\r\n",
      "Status:       Running\r\n",
      "IP:           10.244.1.225\r\n",
      "IPs:\r\n",
      "  IP:           10.244.1.225\r\n",
      "Controlled By:  StatefulSet/logstash-logstash\r\n",
      "Containers:\r\n",
      "  logstash:\r\n",
      "    Container ID:   containerd://bcf6d71add9888f536ee54cd0d36e097423e3bca5c4c32be29be2e3bfe30bcf1\r\n",
      "    Image:          docker.elastic.co/logstash/logstash:7.15.0\r\n",
      "    Image ID:       docker.elastic.co/logstash/logstash@sha256:ba6ee9c11620d0bb9d5bff5937bdf995b71bc7a2bcd1047b1458cf752194b54a\r\n",
      "    Port:           9600/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Running\r\n",
      "      Started:      Sun, 12 Jun 2022 22:05:02 -0400\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  0\r\n",
      "    Limits:\r\n",
      "      cpu:     200m\r\n",
      "      memory:  250Mi\r\n",
      "    Requests:\r\n",
      "      cpu:      100m\r\n",
      "      memory:   250Mi\r\n",
      "    Liveness:   http-get http://:http/ delay=300s timeout=90s period=10s #success=1 #failure=3\r\n",
      "    Readiness:  http-get http://:http/ delay=60s timeout=90s period=10s #success=3 #failure=3\r\n",
      "    Environment:\r\n",
      "      LS_JAVA_OPTS:  -Xmx1g -Xms1g\r\n",
      "    Mounts:\r\n",
      "      /usr/share/logstash/pipeline/logstash.conf from logstashpipeline (rw,path=\"logstash.conf\")\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6skj7 (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  logstashpipeline:\r\n",
      "    Type:      ConfigMap (a volume populated by a ConfigMap)\r\n",
      "    Name:      logstash-logstash-pipeline\r\n",
      "    Optional:  false\r\n",
      "  kube-api-access-6skj7:\r\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\r\n",
      "    TokenExpirationSeconds:  3607\r\n",
      "    ConfigMapName:           kube-root-ca.crt\r\n",
      "    ConfigMapOptional:       <nil>\r\n",
      "    DownwardAPI:             true\r\n",
      "QoS Class:                   Burstable\r\n",
      "Node-Selectors:              doks.digitalocean.com/node-pool=dev-model-services-additional-pool\r\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\r\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\r\n",
      "Events:\r\n",
      "  Type     Reason     Age               From               Message\r\n",
      "  ----     ------     ----              ----               -------\r\n",
      "  Normal   Scheduled  90s               default-scheduler  Successfully assigned logging-system/logstash-logstash-0 to dev-model-services-additional-pool-c2ss9\r\n",
      "  Normal   Pulled     89s               kubelet            Container image \"docker.elastic.co/logstash/logstash:7.15.0\" already present on machine\r\n",
      "  Normal   Created    89s               kubelet            Created container logstash\r\n",
      "  Normal   Started    89s               kubelet            Started container logstash\r\n",
      "  Warning  Unhealthy  0s (x4 over 22s)  kubelet            Readiness probe failed: Get \"http://10.244.1.225:9600/\": dial tcp 10.244.1.225:9600: connect: connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pod logstash-logstash-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c4301aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bundled JDK: /usr/share/logstash/jdk\r\n",
      "OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs logstash-logstash-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d35226",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6a8016ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bundled JDK: /usr/share/logstash/jdk\r\n",
      "OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs logstash-logstash-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fcd82d",
   "metadata": {},
   "source": [
    "Logstash is deployed as a [Service](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/), which is a way to schedule workloads on Kubernetes that need to maintain state. \n",
    "\n",
    "The StatefulSet is also running on the additional node pool. We did this by adding a nodeSelector to the Helm values file, just like Logstash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165aa19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dffee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1a2e582",
   "metadata": {},
   "source": [
    "### Creating the Log Forwarder Service\n",
    "\n",
    "In order to centralize access to logs, we'll first need a way to get the logs off of the individual cluster nodes and forward them to the aggregator service. The service we'll use to do this is called [Filebeat](https://www.elastic.co/beats/filebeat). Filebeat is a lightweight service that can forward logs stored in files to an outside service.\n",
    "\n",
    "To install Filebeat, we'll provide the ./helm/filebeat_values.yaml file to Helm using the elastic/filebeat chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "185cca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: filebeat\r\n",
      "LAST DEPLOYED: Sun Jun 12 21:58:51 2022\r\n",
      "NAMESPACE: logging-system\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "TEST SUITE: None\r\n",
      "NOTES:\r\n",
      "1. Watch all containers come up.\r\n",
      "  $ kubectl get pods --namespace=logging-system -l app=filebeat-filebeat -w\r\n"
     ]
    }
   ],
   "source": [
    "!helm install filebeat elastic/filebeat -f ./helm/filebeat_values.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad802d27",
   "metadata": {},
   "source": [
    "We can view the pods that are running the Filebeat processes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "11c9b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                      READY   STATUS    RESTARTS   AGE\r\n",
      "filebeat-filebeat-6tr9w   0/1     Running   0          36s\r\n",
      "filebeat-filebeat-pdcvp   0/1     Running   0          36s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l app=filebeat-filebeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4b58927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         filebeat-filebeat-pdcvp\r\n",
      "Namespace:    logging-system\r\n",
      "Priority:     0\r\n",
      "Node:         dev-model-services-default-worker-pool-c2spv/10.108.16.2\r\n",
      "Start Time:   Sun, 12 Jun 2022 21:58:53 -0400\r\n",
      "Labels:       app=filebeat-filebeat\r\n",
      "              chart=filebeat-7.17.3\r\n",
      "              controller-revision-hash=5cb557986c\r\n",
      "              heritage=Helm\r\n",
      "              pod-template-generation=1\r\n",
      "              release=filebeat\r\n",
      "Annotations:  configChecksum: 8bff89f37192b6bcf6c9ac083a23400476e58d2aaa210ee43dd98650fa51b5f\r\n",
      "Status:       Running\r\n",
      "IP:           10.244.0.94\r\n",
      "IPs:\r\n",
      "  IP:           10.244.0.94\r\n",
      "Controlled By:  DaemonSet/filebeat-filebeat\r\n",
      "Containers:\r\n",
      "  filebeat:\r\n",
      "    Container ID:  containerd://1ab3612d5de06434cf92fb1f9c73dd1eea95f9ec64715707d7204afcec73e479\r\n",
      "    Image:         docker.elastic.co/beats/filebeat:7.15.0\r\n",
      "    Image ID:      docker.elastic.co/beats/filebeat@sha256:bb436cf141e03a2e5a2dc589971c2f20b621e46380d8f25016f9df4a2dba67a2\r\n",
      "    Port:          <none>\r\n",
      "    Host Port:     <none>\r\n",
      "    Args:\r\n",
      "      -e\r\n",
      "      -E\r\n",
      "      http.enabled=true\r\n",
      "    State:          Running\r\n",
      "      Started:      Sun, 12 Jun 2022 21:59:14 -0400\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  0\r\n",
      "    Limits:\r\n",
      "      cpu:     1\r\n",
      "      memory:  200Mi\r\n",
      "    Requests:\r\n",
      "      cpu:     100m\r\n",
      "      memory:  100Mi\r\n",
      "    Liveness:  exec [sh -c #!/usr/bin/env bash -e\r\n",
      "curl --fail 127.0.0.1:5066\r\n",
      "] delay=10s timeout=5s period=10s #success=1 #failure=3\r\n",
      "    Readiness:  exec [sh -c #!/usr/bin/env bash -e\r\n",
      "filebeat test output\r\n",
      "] delay=10s timeout=5s period=10s #success=1 #failure=3\r\n",
      "    Environment:\r\n",
      "      POD_NAMESPACE:  logging-system (v1:metadata.namespace)\r\n",
      "      NODE_NAME:       (v1:spec.nodeName)\r\n",
      "    Mounts:\r\n",
      "      /usr/share/filebeat/data from data (rw)\r\n",
      "      /usr/share/filebeat/filebeat.yml from filebeat-config (ro,path=\"filebeat.yml\")\r\n",
      "      /var/lib/docker/containers from varlibdockercontainers (ro)\r\n",
      "      /var/log from varlog (ro)\r\n",
      "      /var/run/docker.sock from varrundockersock (ro)\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f2xtt (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  filebeat-config:\r\n",
      "    Type:      ConfigMap (a volume populated by a ConfigMap)\r\n",
      "    Name:      filebeat-filebeat-daemonset-config\r\n",
      "    Optional:  false\r\n",
      "  data:\r\n",
      "    Type:          HostPath (bare host directory volume)\r\n",
      "    Path:          /var/lib/filebeat-filebeat-logging-system-data\r\n",
      "    HostPathType:  DirectoryOrCreate\r\n",
      "  varlibdockercontainers:\r\n",
      "    Type:          HostPath (bare host directory volume)\r\n",
      "    Path:          /var/lib/docker/containers\r\n",
      "    HostPathType:  \r\n",
      "  varlog:\r\n",
      "    Type:          HostPath (bare host directory volume)\r\n",
      "    Path:          /var/log\r\n",
      "    HostPathType:  \r\n",
      "  varrundockersock:\r\n",
      "    Type:          HostPath (bare host directory volume)\r\n",
      "    Path:          /var/run/docker.sock\r\n",
      "    HostPathType:  \r\n",
      "  kube-api-access-f2xtt:\r\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\r\n",
      "    TokenExpirationSeconds:  3607\r\n",
      "    ConfigMapName:           kube-root-ca.crt\r\n",
      "    ConfigMapOptional:       <nil>\r\n",
      "    DownwardAPI:             true\r\n",
      "QoS Class:                   Burstable\r\n",
      "Node-Selectors:              doks.digitalocean.com/node-pool=dev-model-services-default-worker-pool\r\n",
      "Tolerations:                 node.kubernetes.io/disk-pressure:NoSchedule op=Exists\r\n",
      "                             node.kubernetes.io/memory-pressure:NoSchedule op=Exists\r\n",
      "                             node.kubernetes.io/not-ready:NoExecute op=Exists\r\n",
      "                             node.kubernetes.io/pid-pressure:NoSchedule op=Exists\r\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists\r\n",
      "                             node.kubernetes.io/unschedulable:NoSchedule op=Exists\r\n",
      "Events:\r\n",
      "  Type     Reason     Age   From               Message\r\n",
      "  ----     ------     ----  ----               -------\r\n",
      "  Normal   Scheduled  40s   default-scheduler  Successfully assigned logging-system/filebeat-filebeat-pdcvp to dev-model-services-default-worker-pool-c2spv\r\n",
      "  Normal   Pulling    39s   kubelet            Pulling image \"docker.elastic.co/beats/filebeat:7.15.0\"\r\n",
      "  Normal   Pulled     20s   kubelet            Successfully pulled image \"docker.elastic.co/beats/filebeat:7.15.0\" in 19.384384305s\r\n",
      "  Normal   Created    19s   kubelet            Created container filebeat\r\n",
      "  Normal   Started    19s   kubelet            Started container filebeat\r\n",
      "  Warning  Unhealthy  0s    kubelet            Readiness probe failed: logstash: logstash-logstash:5044...\r\n",
      "  connection...\r\n",
      "    parse host... OK\r\n",
      "    dns lookup... ERROR lookup logstash-logstash on 10.245.0.10:53: no such host\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pod filebeat-filebeat-pdcvp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88990d",
   "metadata": {},
   "source": [
    "The Filebeat pods are running inside of a [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/), which is a way to schedule pods in Kubernetes that guarantees that a pod will run on all nodes. We have two nodes running on the worker node pool of the cluster so we see two pods listed above.\n",
    "\n",
    "The DaemonSet is actually not running on the nodes in the additional node pool we set up using Terraform above. This was done by adding a nodeSelector section to the Helm values file for the Filebeat installation:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "nodeSelector:\n",
    "    doks.digitalocean.com/node-pool: \"dev-model-services-default-worker-pool\"\n",
    "...\n",
    "```\n",
    "\n",
    "This nodeSelector guarantees that we'll only run the log forwarding processes in the default worker pool of the cluster which is running the model service. This is to be able to keep the workloads separated in two different node pools, the default pool is for the model services, and the additional node pool is for the supporting services like the logging system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b88c52",
   "metadata": {},
   "source": [
    "## Viewing the Logs\n",
    "\n",
    "A Kibana dashboard specifically for the model, created by using the fields that were added by the decoratorâ€¦\n",
    "\n",
    "\n",
    "Number of predictions...\n",
    "\n",
    "Number of exceptions...\n",
    "\n",
    "Number of predictions per instance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976336b",
   "metadata": {},
   "source": [
    "## Deleting the Resources\n",
    "\n",
    "Now that we're done with the service we need to destroy the resources. \n",
    "\n",
    "To delete the logging system, we'll delete the helm deployments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "bb1b4b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"filebeat\" uninstalled\n",
      "release \"logstash\" uninstalled\n",
      "release \"elasticsearch\" uninstalled\n",
      "release \"kibana\" uninstalled\n"
     ]
    }
   ],
   "source": [
    "!helm uninstall filebeat\n",
    "!helm uninstall logstash\n",
    "!helm uninstall elasticsearch\n",
    "!helm uninstall kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efdf3b",
   "metadata": {},
   "source": [
    "The persistent volume claims are not deleted along with the deployments, so we'll list them and then delete them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1f17eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE\r\n",
      "elasticsearch-master-elasticsearch-master-0   Bound    pvc-a5788ff6-1165-48a2-a55e-3ca3409f4501   30Gi       RWO            do-block-storage   67m\r\n",
      "elasticsearch-master-elasticsearch-master-1   Bound    pvc-0721169a-345f-41ac-9d91-deb166e54f09   30Gi       RWO            do-block-storage   67m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1095f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim \"elasticsearch-master-elasticsearch-master-0\" deleted\n",
      "persistentvolumeclaim \"elasticsearch-master-elasticsearch-master-1\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete pvc -l app=elasticsearch-master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925c6fe",
   "metadata": {},
   "source": [
    "Now we can delete the logging system's namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f717e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace \"logging-system\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f kubernetes/logging_namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78903c33",
   "metadata": {},
   "source": [
    "To delete the model service kubernetes resources, we'll execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2825ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"do-nyc3-dev-model-services-cluster\" modified.\n",
      "deployment.apps \"insurance-charges-model-deployment\" deleted\n",
      "service \"insurance-charges-model-service\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context --current --namespace=model-services\n",
    "!kubectl delete -f ./kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f64c43",
   "metadata": {},
   "source": [
    "We'll also delete the model service namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5f5186f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace \"model-services\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f kubernetes/namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541f396",
   "metadata": {},
   "source": [
    "Lastly, we'll need to delete the cloud infrastructure using the Terraform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "039e528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/logging-for-ml-models/terraform\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_container_registry.container_registry: Refreshing state... [id=dev-model-services-container-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Refreshing state... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Refreshing state... [id=cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_project.project: Refreshing state... [id=a4470669-8c90-468a-9bdb-5e3a27428eff]\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Refreshing state... [id=0734e25f-54da-465d-a6ca-833678b6b067]\u001b[0m\n",
      "\n",
      "Terraform used the selected providers to generate the following execution plan.\n",
      "Resource actions are indicated with the following symbols:\n",
      "  \u001b[31m-\u001b[0m destroy\n",
      "\u001b[0m\n",
      "Terraform will perform the following actions:\n",
      "\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_container_registry.container_registry\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_container_registry\" \"container_registry\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m             = \"2022-06-12 22:22:33 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m               = \"registry.digitalocean.com/dev-model-services-container-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                     = \"dev-model-services-container-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m                   = \"dev-model-services-container-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m                 = \"nyc3\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mserver_url\u001b[0m\u001b[0m             = \"registry.digitalocean.com\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstorage_usage_bytes\u001b[0m\u001b[0m    = 729882624 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msubscription_tier_slug\u001b[0m\u001b[0m = \"basic\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_cluster\" \"cluster\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_upgrade\u001b[0m\u001b[0m   = true \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_subnet\u001b[0m\u001b[0m = \"10.244.0.0/16\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m     = \"2022-06-12 22:22:30 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m       = \"https://cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da.k8s.ondigitalocean.com\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mha\u001b[0m\u001b[0m             = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m             = \"cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mkube_config\u001b[0m\u001b[0m    = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m           = \"dev-model-services-cluster\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m         = \"nyc3\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mservice_subnet\u001b[0m\u001b[0m = \"10.245.0.0/16\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstatus\u001b[0m\u001b[0m         = \"running\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msurge_upgrade\u001b[0m\u001b[0m  = true \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m           = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m     = \"2022-06-13 00:43:31 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m            = \"do:kubernetes:cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mversion\u001b[0m\u001b[0m        = \"1.22.8-do.1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mvpc_uuid\u001b[0m\u001b[0m       = \"b96875c9-ed67-46d7-892e-3a3c4d9329c0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mmaintenance_policy {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mday\u001b[0m\u001b[0m        = \"sunday\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mduration\u001b[0m\u001b[0m   = \"4h0m0s\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstart_time\u001b[0m\u001b[0m = \"04:00\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mnode_pool {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = 2 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = \"0a6d2c5d-a5be-424d-be43-bce66aa9e547\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mlabels\u001b[0m\u001b[0m            = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmax_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmin_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"dev-model-services-default-worker-pool\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 2 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = [\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-06-12 22:22:30 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"303892527\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"866ada4d-aa24-425e-9949-d7a1ba5aefc7\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"dev-model-services-default-worker-pool-c2spi\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-06-12 22:24:00 +0000 UTC\"\n",
      "                },\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-06-12 22:22:30 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"303892526\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"2cd36dab-f681-43e6-bc7b-9529d51d6f81\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"dev-model-services-default-worker-pool-c2spv\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-06-12 22:24:00 +0000 UTC\"\n",
      "                },\n",
      "            ] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-1vcpu-2gb\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m              = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_node_pool\" \"additional_pool\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = 2 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_id\u001b[0m\u001b[0m        = \"cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = \"0734e25f-54da-465d-a6ca-833678b6b067\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mlabels\u001b[0m\u001b[0m            = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmax_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmin_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"dev-model-services-additional-pool\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 2 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = [\n",
      "          \u001b[31m-\u001b[0m \u001b[0m{\n",
      "              \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-06-12 22:28:02 +0000 UTC\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"303892797\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mid         = \"96963518-6e45-4839-8829-a4ef4854e043\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mname       = \"dev-model-services-additional-pool-c2ss9\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-06-12 22:28:49 +0000 UTC\"\n",
      "            },\n",
      "          \u001b[31m-\u001b[0m \u001b[0m{\n",
      "              \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-06-12 22:28:02 +0000 UTC\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"303892796\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mid         = \"9c522467-1824-444d-8e5a-8696ffcb8ac2\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mname       = \"dev-model-services-additional-pool-c2s5n\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "              \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-06-12 22:28:49 +0000 UTC\"\n",
      "            },\n",
      "        ] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-2vcpu-4gb\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m              = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_project.project\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_project\" \"project\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = \"2022-06-12T22:28:01Z\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = \"a4470669-8c90-468a-9bdb-5e3a27428eff\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mis_default\u001b[0m\u001b[0m = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"dev-model-services\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mowner_id\u001b[0m\u001b[0m   = 9331917 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mowner_uuid\u001b[0m\u001b[0m = \"7c8b77fc-0761-47a4-8c2c-2b7736e09ddd\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mpurpose\u001b[0m\u001b[0m    = \"Web Application\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mresources\u001b[0m\u001b[0m  = [\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\"do:kubernetes:cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da\",\n",
      "        ] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m = \"2022-06-12T22:28:01Z\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # module.kubernetes_cluster.digitalocean_vpc.cluster_vpc\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_vpc\" \"cluster_vpc\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = \"2022-06-12 22:22:28 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdefault\u001b[0m\u001b[0m    = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = \"b96875c9-ed67-46d7-892e-3a3c4d9329c0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mip_range\u001b[0m\u001b[0m   = \"10.108.16.0/20\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"dev-model-services-vpc\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m     = \"nyc3\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m        = \"do:vpc:b96875c9-ed67-46d7-892e-3a3c4d9329c0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mtimeouts {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdelete\u001b[0m\u001b[0m = \"10m\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[0m\u001b[1mPlan:\u001b[0m 0 to add, 0 to change, 5 to destroy.\n",
      "\u001b[0m\u001b[90m\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\n",
      "Saved the plan to: tfplan\n",
      "\n",
      "To perform exactly these actions, run the following command to apply:\n",
      "    terraform apply \"tfplan\"\n"
     ]
    }
   ],
   "source": [
    "%cd ./terraform\n",
    "\n",
    "!terraform plan -destroy -out=tfplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eb74b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_project.project: Destroying... [id=a4470669-8c90-468a-9bdb-5e3a27428eff]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_container_registry.container_registry: Destroying... [id=dev-model-services-container-registry]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Destroying... [id=0734e25f-54da-465d-a6ca-833678b6b067]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_container_registry.container_registry: Destruction complete after 1s\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_project.project: Destruction complete after 3s\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still destroying... [id=0734e25f-54da-465d-a6ca-833678b6b067, 10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Still destroying... [id=0734e25f-54da-465d-a6ca-833678b6b067, 20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_node_pool.additional_pool[0]: Destruction complete after 21s\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Destroying... [id=cf9dd0d1-b67a-43fa-a7d2-f3b30d35d2da]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_kubernetes_cluster.cluster: Destruction complete after 1s\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 1m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 1m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 1m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 1m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 1m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 1m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 2m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 2m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Still destroying... [id=b96875c9-ed67-46d7-892e-3a3c4d9329c0, 2m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.kubernetes_cluster.digitalocean_vpc.cluster_vpc: Destruction complete after 2m21s\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 0 added, 0 changed, 5 destroyed.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!terraform apply -auto-approve -destroy tfplan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52f6a0",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "In this blog post we showed how to do logging with the Python logging package, and how to create a decorator that can help us to do logging around an MLModel. We also set up and used a logging system within a Kubernetes cluster and used it to aggregate logs and view them. Logging is usually the first thing that is implemented when we need to monitor how a system performs, and machine learning models are no exception to this. The logging decorator allowed us to do complex logging without having to modify the implementation of the model at all, thus simplifying a common aspect of software observability.\n",
    "\n",
    "One of the benefits of using the decorator pattern is that we are able to build up complex behaviors around an object by combining decorator instances in the right order. We saw how to do this when we added a unique id to each prediction that the model made by adding the PredictionIDDecorator to the configuration. The prediction_id field was then added to the configuration of the LoggingDecorator as an extra field to add to the log records it produced. This approach allowed us to add a unique identifier to each prediction and also log the identifier with each log generated by the logging decorator, and we didnt have to write new code to do it.\n",
    "\n",
    "The LoggingDecorator class is very configurable, since we are able to configure it to log input and output fields from the model. This approach makes the implementation very flexible, since we do not need to modify the decorator's code to add fields to the log. The EnvironmentInfoFilter class that we implemented to grab information from the environment for logs is also built this way. We were able to get information about the Kubernetes deployment from the logs without having to modify the code at all.\n",
    "\n",
    "The LoggingDecorator class is designed to work with MLModel classes, and this is the only hard requirement of the code. This makes the decorator very portable, because we are able to deploy it inside of any other model deployment service we may choose to build in the future. For example, we can just as easily decorate an MLModel instance runnning inside of an gRPC service, since the decorator would work exactly the same way. This is due to interface-driven approach that we took when designing the MLModel interface.\n",
    "\n",
    "The fact is that we added logging to the ML model from the \"outside\" and we were not able to access information about the internals of the model. This is a limitation of the decorator approach to logging which only has access to the model inputs, model outputs, and exceptions raised by the model. This approach is best used to add logging functionality to an ML model implementation that we do not control, or in simple situations in which the limitations of the approach do not affect us. If any logging of internal model state is needed, we'll need to generate logs from within the MLModel class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
